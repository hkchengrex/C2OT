defaults:
  - base_config
  - override hydra/job_logging: custom
  - _self_

hydra:
  run:
    dir: ./output/cifar/${exp_id}
  output_subdir: train-${now:%Y-%m-%d_%H-%M-%S}-hydra

amp: True

dataset: cifar
num_classes: 10
size: 32
data_path: ../data/cifar
conditional: True
conditioning_code: class
code_dim: -1
use_memmap: False

# fm / ot / ot-cls
fm_type: fm
cls_weight: 1e8
condition_norm: l2_squared

model: unet-large

# ema configuration
ema_decay: 0.9999

log_text_interval: 200
log_extra_interval: 20_000
# eval_interval: 10_000
eval_interval: 100_000
save_weights_interval: 10_000
save_checkpoint_interval: 10_000
save_copy_iterations: []
save_copy_always: True

batch_size: 256 # effective
ot_batch_size: null # effective
eval_batch_size: 512 # per-GPU

num_iterations: 100_000
learning_rate: 2.0e-4
linear_warmup_steps: 5_000

lr_schedule: constant
# lr_schedule_steps: [240_000, 270_000]
# lr_schedule_gamma: 0.1

clip_grad_norm: 1.0
weight_decay: 0.0
dropout: 0.0